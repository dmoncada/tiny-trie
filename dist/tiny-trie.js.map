{"version":3,"sources":["webpack://TinyTrie/webpack/universalModuleDefinition","webpack://TinyTrie/webpack/bootstrap","webpack://TinyTrie/./src/BinaryString.ts","webpack://TinyTrie/./src/Trie.ts","webpack://TinyTrie/./src/base64.ts","webpack://TinyTrie/./src/constants.ts","webpack://TinyTrie/./src/floor_log2.ts","webpack://TinyTrie/./src/index.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA,yDAAiD,cAAc;AAC/D;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;;AAGA;AACA;;;;;;;;;;;;;;;;;;;;AC9DA,uCAAwC;AACxC,mCAMA;;;AAAA;;;AAMY,aAAM,SAAK;AASX,aAAO,UAAK;AAMZ,aAAI,OA6EhB;AAAC;;;;8BAlEoB;gBAAE,4EAAoB;;AACnC,gBAAO,MAAO,KAAQ;AACtB,gBAAO,MAAQ,SAAI,aAAU,WAAK,OAAK;AAEpC,gBAAM,SAAW,OAAI,OAAW,OAAE;AACjC,sBAAM,IAAU,uBAAkB,oBACtC;AAAC;AAEG,iBAAO,SAAO,OAAQ,GAAZ,GAAmB;AAC7B,iBAAQ,WAAQ;AAEhB,iBACR;AAMK;;;;AACD,gBAAU,SAAO,KAAQ;AACzB,gBAAW,UAAO,KAAS;AAE3B,mBAAc,WAAW,UAAI,GAAG;AACtB,2BAAO;AACN,2BACX;AAAC;AACG,iBAAQ,UAAW;AACnB,iBAAO,SAAU;AACjB,iBACR;AAOO;;;;AACC,iBAAS;AACP,mBAAK,KACf;AAWO;;;;AACH,gBAAU,SAAO,KAAQ;AACzB,gBAAW,UAAO,KAAS;AAC3B,gBAAW,UAAM;AACjB,mBAAc,WAAK,GAAG;AAClB,oBAAgB,YAAQ,UAAM;AAC9B,oBAAQ,OAAS,UAAc;AACzB,yBAAY,SAAK,QAAe;AAC/B,0BAAa;AACb,2BAAI,SAAkB,mBACjC;AAAC;AACG,iBAAQ,UAAW;AACnB,iBAAO,SAAU;AACjB,iBAAK,QACb;AAEH;;;;;;AAlGD,uBAkGC,a;;;;;;;;;;;;;;;;;;;;;;;ACzGD,uCAAwC;AACxC,yCAA4C;AAC5C,sCAgDA;;;AAcI;YAAY,2EAAgB;;;;AACpB,aAAK,OAAQ;AACb,aAAO,SACf;AASM;;;;+BAAY;AAGX,gBAAK,KAAQ,QAAE;AACd,sBAAM,IACV;AAAC;AAED,gBAAc,eAAY,MAAI,IAAO,OAAC,UAAK,MAAU;AAC9C,oBAAK,SAAK,YAAS,UAAE;AACpB,0BAAM,IAAc,wCAA4B,YACpD;AAAC;AACD,oBAAY,WAAO,KAAe,eAAQ,QAClC,KACJ,QAAK,KAAM,QAAO;AAChB,uBACV;AAAC,aARmB,EAQb,KAAO;AAKN,qBAAC,YAAS,YAAG,YAAS;AAExB,mBACV;AASI;;;6BAAc;2FAAgC,EAAS,UAAM,MAAQ,QAAQ;gBAAtD;gBAAQ;;AAE5B,gBAAC,CAAU,UAAE;AACZ,oBAAQ,OAAO,KAAM;AACrB,oBAAW,YAAY,MAAI,IAAM;AAAQ,2BAAC,CAAE,EAAK,OAAO,KAAS;iBAAhD;AACX,uBAAC,CAAC,CAAU,UAAO,UAAQ,KAAe,eAAC,YACrD;AAAC;AAGK,mBAAC,CAAC,CAAK,KAAO,OAAI,KAAE,EAAS,oBAAQ,gBAAO,OACtD;AAmBM;;;+BAAc;4FAAyC,EAAS,UAAM,MAAQ,QAAO,OAAO,OAAQ;gBAA7E;gBAAQ;gBAAO;;AAErC,gBAAS,YAAY,SAAO,WAAO,GAAE;AACpC,sBAAM,IAAU,0CAA0C,SAC9D;AAAC;AAGD,gBAAa,UAAM;AAGnB,gBAAW,QAAG,CAAC,EAAK,MAAM,KAAK,MAAO,OAAG,GAAM,MAAO;AACtD,gBAAe,YAAM,IAAQ;;;AAGzB,oBAAU,OAAQ,MAAS;AAIxB,oBAAK,KAAM,SAAc,WAAE;AACvB,wBAAK,KAAK,KAAe,eAAC,YAAU,WAAE;AAClC,4BAAO,OAAE;AACF;mCAAK,KACf;;AAAC;AAEM,gCAAK,KAAK,KACrB;AAAC;AAGE,wBAAC,CAAQ,QAAE;AAEd;AACJ;AAAC;AAGD,oBAAmB,gBAAS,UAAQ,KAAM,SAAc;AAExD,oBAAW,QAAM,IAAK,KAAQ;AAE3B,oBAAM,UAAa,YAAkB,eAAE;AAChC,2BAAK,KAAK,KAAM,MAAQ,QAAK;AAC5B,4BAAE,MAAK,YAAS,UAAE;AACZ,kCAAK;AACF,sCAAM,KAAK,KAAG;AACb,uCAAM,KAAM,QAAI;AACjB,sCAAM,KAAK,OAEvB;AALe;AAMnB;AACJ;AAAM,uBAAE;AACD,wBAAK,KAAK,KAAe,eAAQ,QAAE;AAC7B,8BAAK;AACF,kCAAM,KAAK,KAAO;AACjB,mCAAM,KAAM,QAAI;AACjB,kCAAM,KAAK,OAEvB;AALe;AAMnB;AACJ;;;AA5CA,mBAAY,MAAO;AAAG;;;;;;;;;AA4CrB;AAIK,mBAAQ,QAAO,OACzB;AAMK;;;;AACK,mBAAC,IAAQ,KAAK,KACxB;AAOM;;;;AAEC,gBAAK,KAAQ,QAAE;AACR,uBACV;AAAC;AAGD,gBAAgB,aAAgC;AAGhD,gBAAQ,OAAO,KAAM;AACrB,gBAAS,QAAuD;AAChE,gBAAc,aAAG,CAAO;AAKxB,mBAAiB,WAAO,QAAG;AACnB,uBAAa,WAAO;AAElB,uBAAK,KAAM,MAAQ,QAAQ;AAC1B,wBAAK,KAAG,OAAS,KAAE;AAEtB;AAAC;AACD,wBAAW,UAAO,KAAO;AACpB,0BAAK;AACC,iCAAS;AACZ,8BAAM;AACJ,gCACP;AAJQ;AAKD,+BAAK,KACnB;AACJ;AAAC;;;iCAIwC,MAAO;oBAAlC;oBAAQ;oBAAW;;AAG1B,oBAAW,WAAe,eAAO,OAAE;AAClC,wBAAc,aAAa,WAAO;AAKlC,wBAAS,mBAAkB,KAAS;AAChC,4BAAS,QAAS,OAAK,KAAQ;AAC/B,4BAAS,QAAS,OAAK,KAAU;AAC1B,+BACE,MAAO,WAAU,MAAO,gBAClB;AAAO,mCAAM,MAAK,SAAY,QAEjD;yBAFa;AAEV,qBAPmB;AAWnB,wBAAO,OAAE;AACF,+BAAM,QAChB;AAEI,2BAAE;AACQ,mCAAK,KACnB;AACJ;AAEI,uBAAE;AACQ,+BAAM,QAAG,CACvB;AACJ;;;AAjCA,mBAAY,MAAO;AACX;AAgCP;AAGG,iBAAO,SAAQ;AAEb,mBACV;AAOM;;;;AACF,gBAAY,SAAgB;AAC5B,gBAAW,QAAG,CAAK,KAAO;AAC1B,gBAAe,YAAG,IAAU;AAC5B,gBAAe,YAAO,KAAO;AAC7B,gBAAa,YAAY;AACzB,gBAAa,YAAG,CAAU;;;AAOtB,oBAAQ,OAAQ,MAA0B;AAC1C,oBAAQ,cAAc,KAAM,MAAO;AAAK,2BAAE,EAAG,OAAU;iBAAtC;AACjB,oBAAK,IAAO,KAAQ;AAEhB,qBAAY,cAAa;AAC7B,oBAAkB,iBAAO,KAAQ,UAAS,OAAQ;AAI/C,oBAAK,KAAa,aAAE;AACf,yBAAY,YAAQ,QAAS;AAC7B,4BAAU,SAAQ,MAAO,SAAiB,iBAAQ,MAAK;AACpD,4BAAO,SAAa,WAAE;AACZ,wCACb;AAAC;AACE,4BAAO,SAAa,WAAE;AACZ,wCACb;AACJ;AACJ;AAAC;AAEG,qBAAQ,QAAC,UAAK,MAAO;AACrB,wBAAS,QAAO,KAAwB;AACxC,wBAAY,WAAS,OAAQ;AAC7B,wBAAe,cAAI,MAAM,IAAK;AAE9B,wBAAY;AACJ,8BAAM;AACP,6BAAU;AACP,gCAAM;AACR,8BACN;AALqB;AASpB,wBAAM,MAAY,gBAAe,WAAE;AAClC,4BAAO,MAAQ,MAAS;AACxB,4BAAU,SAAW,SAAO,SAAM,MAAY;AAC3C,4BAAO,SAAa,WAAE;AACZ,wCACb;AAAC;AACE,4BAAO,SAAa,WAAE;AACZ,wCACb;AACJ;AAGI,2BAAE;AACC,4BAAM,MAAc,kBAAe,WAAE;AAC/B,kCAAY,YAAK,KAC1B;AAAM,+BAAE;AACC,kCAAc,gBAAa;AAC3B,kCAAY,cAAG,CACxB;AAAC;AACI,8BAAK,KACd;AAAC;AAGK,2BAAK,KAAW;AAGb,8BAAI,IACjB;AACJ;;;AAhEA,mBAAY,MAAO;AAAG;AAgErB;AAMD,gBAAsB,yBAAa,KAAW,WACnC;AAAQ,uBAAK,SAAK,YAAU;aADT;AAE9B,gBAAa,2BAA0B,OAAC,UAAI,KAAM,MAAO;AAClD,oBAAM,QAAI,IAAK;AACZ,uBACV;AAAK,aAH2B,sBAG1B,YAAS,UAAO;AAEtB,gBAAuB,oBAAG,aAAU,WAAiB,iBAAQ,UAAK;AAElE,gBAAkB,eAAY,YAAa;AAC3C,gBAA0B,uBAAG,aAAU,WAAc,gBAAK;AAuC1D,gBAAiB,cAAG,IAAI,eAAe;AAEjC,mBAAQ,QAAS;AACf,oBAAM,OAAyB;oBAAjB;oBAAQ;;AACf,4BAAM,MAAQ,QAAM,OAAqB;AACzC,4BAAM,MAAO,SAAY,WAAwB;AACjD,4BAAM,MAAC,CAAK,MAC3B;AAAG;AAEQ,wBAAS;AAMpB,gBAAkB,eAAG,IAAI,eAAe;AAExC,gBAAqB,kBAAmB,iBAAK,KAAK;AAIlD,gBAAiB,cAAO,KAAK,KAAC,CAC1B,YAAkB,qBAClB,YAAa,gBACb,YAAiB,oBACjB,YAAgB,mBAChB,YAAgB,mBAChB,YACH,uBAAK,KAAkB,gBAAQ;AAEhC,gBAAgB,aAAI,EAAU,YAAM;AAExB,yBAAM,MAAY,aAAE,YAAoB;AACxC,yBAAM,MAAC,YAAO,SAAE,YAAe;AAC/B,yBAAM,MAAW,YAAE,YAAmB;AACtC,yBAAM,MAAa,aAAC,CAAY,YAAU,WAAE,YAAkB;AAC9D,yBAAM,MAAkB,mBAAE,YAAkB;AAC5C,yBAAM,MAAqB,sBAAE,YAAqB;AAClD,yBAAS;AAGd,wBAAe,aAAU,YAAkB,kBAAc,YACpE;AAkBM;;;;AAEF,gBAAO,WAAiB,UAAK,KAAK,MAAE,UAAE,GAAO;AACrC,oBAAE,EAAG,OAAS,KAAE;AACV,2BACT;AAAC;AACK,uBACX;AAAG,aALW;AAMR,mBAAK,KAAM,MACrB;AAEH;;;;;;AA/bD,eA+bC,K;;;;;;;;;;;;;;;AC7eY,QAAkB,qBAK9B,mEAAM,MAAK;AAOC,QAAkB,6BAAqB,mBAAO,OAAC,UAAI,KAAM,MAAO;AACtE,QAAM,QAAK;AACR,WACV;AAAC,CAHiC,EAGA,I;;;;;;;;;;;;;;;AChBrB,QAAQ,WAAQ;AAMhB,QAAQ,WAAS,OAAO,OAAO;AAM/B,QAAO,UAAK;AAOZ,QAAkB,qBAAM;AAMxB,QAAa,gBAAM;AAMnB,QAAiB,oBAAK;AAMtB,QAAgB,mBAAM;AAMtB,QAAgB,mBAAK;AAMrB,QAAmB,sBAAK,E;;;;;;;;;;;;;;;AChDrC,oBAAoC;AAChC,QAAK,IAAK;AACV,WAAQ,MAAM,GAAG;AAEjB;AAAC;AACK,WACV;AAAC;AAND,qBAMC,W;;;;;;;;;;;;;;;ACXD,iCAA4B;AAC5B,iCAA4B;AAApB,sBAAI;AAOZ,oBAA4C;AACxC,QAAU,OAAG,IAAI,OAAO;AAEjB,YAAQ;AAAK,eAAK,KAAO,OAAK;;AAE/B,WACV;AAAC;AAND,qBAMC;AAOD,0BAAgD;AACtC,WAAW,WAAO,OAC5B;AAAC;AAFD,2BAEC,iB","file":"tiny-trie.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"TinyTrie\"] = factory();\n\telse\n\t\troot[\"TinyTrie\"] = factory();\n})(window, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = \"./src/index.ts\");\n","/**\n * @file Provide an interface for writing binary data into a Base64-encoded\n * string.\n */\n\nimport {floor_log2} from './floor_log2';\nimport {BASE64_INT_TO_CHAR} from './base64';\n\n/**\n * Interface for writing binary data into a Base64-encoded string\n * @class\n */\nexport class BinaryString {\n\n    /**\n     * Data buffer\n     * @type {Number?}\n     */\n    private buffer = 0;\n\n    /**\n     * Word pointer for buffer. With every entry into the buffer, the\n     * pointer gets incremented by the entry's width. Every six characters\n     * may be encoded, so when the pointer exceeds 6, the buffer can be\n     * emptied until the pointer is back under 6.\n     * @type {Number}\n     */\n    private pointer = 0;\n\n    /**\n     * Encoded data as a string of base64 characters\n     * @type {String}\n     */\n    private data = '';\n\n    /**\n     * Write a value to the binary string. This value should be thought of as\n     * an integer representing the binary data to write.\n     * @param  {Integer} val - data to write\n     * @param  {Integer} [width] - optionally specify a width for this data.\n     *                             if none is given, width will be inferred\n     *                             automatically. An error will be thrown if\n     *                             the width is too small to contain the data.\n     */\n    write(val: number, width: number = null) {\n        let buf = this.buffer;\n        let len = width || floor_log2(val) + 1;\n\n        if (width && val >= (0x1 << width)) {\n            throw new Error(`Can't write ${val} in only ${width} bits`);\n        }\n\n        this.buffer = (buf << len) | val;\n        this.pointer += len;\n\n        this._digest();\n    }\n\n    /**\n     * Encode the remaining items in the buffer. Use this when the input stream\n     * is finished to ensure that all data has been encoded.\n     */\n    flush() {\n        let buffer = this.buffer;\n        let pointer = this.pointer;\n        // NB if pointer is at 0, there's nothing to flush.\n        while (pointer && pointer < 6) {\n            buffer <<= 1;\n            pointer += 1;\n        }\n        this.pointer = pointer;\n        this.buffer = buffer;\n        this._digest();\n    }\n\n    /**\n     * Get the binary data as base64. This output does not include padding\n     * characters. This procedure flushes the buffer.\n     * @return {String}\n     */\n    getData() {\n        this.flush();\n        return this.data;\n    }\n\n    /**\n     * Write values from the buffer into the binary encoded string until the\n     * pointer is below 6. Use @link BinaryString#flush to print out all values\n     * regardless of whether they are complete and return the pointer to 0.\n     *\n     * This method is used internally during writes and does not need to be\n     * called explicitly.\n     * @private\n     */\n    _digest() {\n        let buffer = this.buffer;\n        let pointer = this.pointer;\n        let newData = '';\n        while (pointer >= 6) {\n            let remainder = (pointer - 6);\n            let code = buffer >> remainder;\n            buffer = buffer ^ (code << remainder);\n            pointer = remainder;\n            newData += BASE64_INT_TO_CHAR[code];\n        }\n        this.pointer = pointer;\n        this.buffer = buffer;\n        this.data += newData;\n    }\n\n}\n","/**\n * @file Provides the Trie class\n */\n\nimport {ITrie, ITestOpts, ISearchOpts} from './BaseTrie';\nimport {floor_log2} from './floor_log2';\nimport {BinaryString} from './BinaryString';\nimport {\n    TERMINAL,\n    TERMINUS,\n    VERSION,\n    HEADER_WIDTH_FIELD,\n    VERSION_FIELD,\n    OFFSET_SIGN_FIELD,\n    OFFSET_VAL_FIELD,\n    CHAR_WIDTH_FIELD,\n    POINTER_WIDTH_FIELD\n} from './constants';\n\n/**\n * Trie node.\n */\nexport interface INode {\n    [key: string]: INode;\n}\n\n/**\n * Metadata used to process trie.\n */\ninterface INodeMeta {\n    __visited__: number;\n    __willVisit__: number;\n    __idx__: number;\n    __parents__: IChunk[];\n}\n\n/**\n * Interface of a node as it is being processed in the trie.\n */\ntype IInternalNode = INode & INodeMeta;\n\n/**\n * Long-form information to be encoded in binary format.\n */\ninterface IChunk {\n    char: string;\n    idx: number;\n    offset: number;\n    last: boolean;\n}\n\n/**\n * A structure to provide efficient membership tests for a set of strings\n * @class\n */\nexport class Trie implements ITrie {\n\n    public root: INode;\n\n    public frozen: boolean;\n\n    /**\n     * Typically no arguments are needed, but it's possible to instantiate a\n     * Trie from a JSON object that represents it (@see Trie#toJSON).\n     * @constructor\n     * @param  {Object} tree - a trie given as a vanilla JS tree. This will be\n     *                         used as the root node.\n     * @return {Trie}\n     */\n    constructor(tree: INode = {}) {\n        this.root = tree;\n        this.frozen = false;\n    }\n\n    /**\n     * Insert a word into the trie. Insertions into a frozen trie will throw\n     * an error. The\n     * @param  {String} str - string to insert. Note the \\u0000 character is\n     *                        disallowed.\n     * @return {Trie} - this\n     */\n    insert(str: string) {\n        // This trie insert algorithm can't guarantee safe inserts on the DAWG\n        // produced by freezing.\n        if (this.frozen) {\n            throw new SyntaxError(`Can't insert into frozen Trie`);\n        }\n\n        const lastNode = str.split('').reduce((node, char) => {\n            if (char === TERMINAL) {\n                throw new TypeError(`Illegal string character ${TERMINAL}`);\n            }\n            let nextNode = node.hasOwnProperty(char) ?\n                node[char] :\n                (node[char] = {});\n            return nextNode;\n        }, this.root);\n\n        // Terminate the string. Using a constant terminus is not necessary\n        // (and is not be possible in cloned tries), but it uses slightly less\n        // memory and could make certain bugs more obvious.\n        lastNode[TERMINAL] = TERMINUS;\n\n        return this;\n    }\n\n    /**\n     * Test membership in the trie.\n     * @param  {String} str - Search query\n     * @param  {String?} opts.wildcard - See Trie#search wildcard doc\n     * @param  {Boolean?} opts.prefix - See Trie#search prefix doc\n     * @return {Boolean}\n     */\n    test(str: string, {wildcard, prefix}: ITestOpts = {wildcard: null, prefix: false}) {\n        // When there are no wildcards we can use an optimized search.\n        if (!wildcard) {\n            let node = this.root;\n            const match = str.split('').every(char => !!(node = node[char]));\n            return !!match && (prefix || node.hasOwnProperty(TERMINAL));\n        }\n\n        // Unoptimized path: delegate to #search with short-circuiting.\n        return !!this.search(str, {wildcard, prefix, first: true});\n    }\n\n    /**\n     * Query for matching words in the trie.\n     * @param  {String} str - Search query\n     * @param  {String?} opts.wildcard - Wildcard to use for fuzzy matching.\n     *                                   Default is no wildcard; only match\n     *                                   literal query.\n     * @param  {Boolean?} opts.prefix - Perform prefix search (returns true if\n     *                                  any word exists in the trie starts with\n     *                                  the search query). Default is false;\n     *                                  only match the full query.\n     * @param  {Boolean} opts.first - Return only first match that is found,\n     *                                short-circuiting the search. Default is\n     *                                false; return all matches.\n     * @return {String?|String[]} - Return an optional string result when in\n     *                              first-only mode; otherwise return a list\n     *                              of strings that match the query.\n     */\n    search(str: string, {wildcard, prefix, first}: ISearchOpts = {wildcard: null, prefix: false, first: false}) {\n        // Validate wildcard matching.\n        if (wildcard && wildcard.length !== 1) {\n            throw new Error(`Wildcard length must be 1; got ${wildcard.length}`);\n        }\n\n        // List of search hits. Note: not used in `first` mode.\n        const matches = [];\n\n        // Do a BFS over nodes to with fuzzy-matching on the wildcard.\n        const queue = [{data: this.root, depth: 0, memo: ''}];\n        const lastDepth = str.length;\n\n        while (queue.length) {\n            const node = queue.shift();\n            // The search is a hit if we've reached the proper depth and the\n            // node is terminal. The search can break if the query was for\n            // first-only.\n            if (node.depth >= lastDepth) {\n                if (node.data.hasOwnProperty(TERMINAL)) {\n                    if (first) {\n                        return node.memo;\n                    }\n                    // Otherwise store this result and continue searching.\n                    matches.push(node.memo);\n                }\n                // Discard the node and move on if we can; prefix matches need\n                // to traverse everything.\n                if (!prefix) {\n                    continue;\n                }\n            }\n            // Special case: prefix searches overflow the length of the search\n            // queries. Treat these overflowing chars as wildcards.\n            const isPfXOverflow = prefix && node.depth >= lastDepth;\n            // Add any candidate children nodes to the search queue.\n            const token = str[node.depth];\n            // Wildcard could be any child (except terminal).\n            if (token === wildcard || isPfXOverflow) {\n                Object.keys(node.data).forEach(n => {\n                    if (n !== TERMINAL) {\n                        queue.push({\n                            data: node.data[n],\n                            depth: node.depth + 1,\n                            memo: node.memo + n,\n                        });\n                    }\n                });\n            } else {\n                if (node.data.hasOwnProperty(token)) {\n                    queue.push({\n                        data: node.data[token],\n                        depth: node.depth + 1,\n                        memo: node.memo + token,\n                    });\n                }\n            }\n        }\n\n        // A `first` search will have broken out and returned a literal by now;\n        // other searches just return whatever is in matches.\n        return first ? null : matches;\n    }\n\n    /**\n     * Clone a Trie. This will unfreeze a frozen trie.\n     * @return {Trie}\n     */\n    clone() {\n        return new Trie(this.toJSON());\n    }\n\n    /**\n     * Freeze the Trie, deduping suffixes. Given the assumption that there will\n     * not be new entries into a trie, redundant suffix branches can be merged.\n     * @return {Trie} - This trie (freezing modifies it in place)\n     */\n    freeze() {\n        // Freezing is idempotent\n        if (this.frozen) {\n            return this;\n        }\n\n        // Create a store for fast lookup of matching suffixes during walk\n        const suffixTree: {[key: string]: INode[]} = {};\n\n        // Walk the entire trie depth first, de-duping suffixes\n        let node = this.root;\n        let stack: {current: INode, char: string, parent: INode}[] = [];\n        let depthStack = [node];\n\n        // Iterate over tree nodes, pushing children onto the depthStack so\n        // that the items pushed on to the main `stack` are in the correct\n        // order for a second traversal.\n        while (depthStack.length) {\n            node = depthStack.pop();\n\n            Object.keys(node).forEach(char => {\n                if (char[1] === '_') {\n                    return;\n                }\n                let current = node[char];\n                stack.push({\n                    current: current,\n                    char: char,\n                    parent: node\n                });\n                depthStack.push(current);\n            });\n        }\n\n        // Now do node processing, joining / deduping suffix lines.\n        while (stack.length) {\n            let { char, parent, current } = stack.pop();\n\n            // Find potential suffix duplicates with a char lookup\n            if (suffixTree.hasOwnProperty(char)) {\n                let suffixMeta = suffixTree[char];\n\n                // Find a matching suffix by comparing children. Since\n                // deduping is depth-first, comparing children by identity\n                // is a valid way to check if this node is a duplicate.\n                let match = suffixMeta.find(other => {\n                    let oKeys = Object.keys(other);\n                    let cKeys = Object.keys(current);\n                    return (\n                        oKeys.length === cKeys.length &&\n                        oKeys.every(key => other[key] === current[key])\n                    );\n                });\n\n                // If this node is a dupe, update its parent reference to\n                // point to the cached match.\n                if (match) {\n                    parent[char] = match;\n                }\n                // If the node is novel, cache it for future checks.\n                else {\n                    suffixMeta.push(current);\n                }\n            }\n            // If this char is novel, create a new suffixMeta entry\n            else {\n                suffixTree[char] = [current];\n            }\n        }\n\n        // Flag the tree as frozen\n        this.frozen = true;\n\n        return this;\n    }\n\n    /**\n     * Encode the Trie in a binary format. This format stores the trie or DAWG\n     * efficiently and still allows for fast queries.\n     * @return {Object}\n     */\n    encode() {\n        const chunks: IChunk[] = [];\n        const queue = [this.root];\n        const charTable = new Set();\n        const visitCode = Date.now();\n        let offsetMin = Infinity;\n        let offsetMax = -Infinity;\n\n        // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        // Encode trie\n        // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n        while (queue.length) {\n            let node = queue.shift() as IInternalNode;\n            let keys = Object.keys(node).filter(k => k[1] !== '_');\n            let n = keys.length;\n\n            node.__visited__ = visitCode;\n            let nodeChunkIndex = node.__idx__ = chunks.length;\n\n            // Fill in the parent chunks that are waiting to find out what\n            // index this chunk gets assigned\n            if (node.__parents__) {\n                node.__parents__.forEach(chunk => {\n                    let offset = chunk.offset = nodeChunkIndex - chunk.idx;\n                    if (offset < offsetMin) {\n                        offsetMin = offset;\n                    }\n                    if (offset > offsetMax) {\n                        offsetMax = offset;\n                    }\n                });\n            }\n\n            keys.forEach((char, i) => {\n                let child = node[char] as IInternalNode;\n                let chunkIdx = chunks.length;\n                let lastInLevel = i === n - 1;\n\n                let newChunk: IChunk = {\n                    char: char,\n                    idx: chunkIdx,\n                    offset: null,\n                    last: lastInLevel\n                };\n\n                // If the child has been visited, jump directly to that node\n                // instead of creating a new entry.\n                if (child.__visited__ === visitCode) {\n                    let idx = child.__idx__;\n                    let offset = newChunk.offset = idx - chunkIdx;\n                    if (offset < offsetMin) {\n                        offsetMin = offset;\n                    }\n                    if (offset > offsetMax) {\n                        offsetMax = offset;\n                    }\n                }\n                // If child is novel, add it to the process queue and add an\n                // instruction to jump there.\n                else {\n                    if (child.__willVisit__ === visitCode) {\n                        child.__parents__.push(newChunk);\n                    } else {\n                        child.__willVisit__ = visitCode;\n                        child.__parents__ = [newChunk];\n                    }\n                    queue.push(child);\n                }\n\n                // Add a new chunk to the array\n                chunks.push(newChunk);\n\n                // Ensure that the char is in the chartable\n                charTable.add(char);\n            });\n        }\n\n        // Assign a unique integer ID to each character. The actual ID is\n        // arbitrary. For the convenience of not having to serialize the \\0\n        // character, the TERMINAL is always encoded at the 0 index, and it is\n        // not included in the charTable.\n        const charTableAsArray = Array.from(charTable)\n            .filter(char => char !== TERMINAL);\n        const charMap = charTableAsArray.reduce((agg, char, i) => {\n            agg[char] = i + 1;\n            return agg;\n        }, { [TERMINAL]: 0 });\n        // Determine the number of bits that can index the entire charTable.\n        const charEncodingWidth = floor_log2(charTableAsArray.length) + 1;\n\n        const pointerRange = offsetMax - offsetMin;\n        const pointerEncodingWidth = floor_log2(pointerRange) + 1;\n\n        // The binary with of node encodings is variable. There are three parts\n        // that get encoded:\n        //\n        //  1) character index (corresponding to character table),\n        //  2) pointer (as offset from start of word to next node),\n        //  3) last (flag to indicate whether this is the last block in this\n        //     subtree)\n        //\n        // The width of the first two items are determined as the binary width\n        // of the unsigned integer representing the maximum in the range. The\n        // width of the third is a constant 1 binary digit.\n        //\n        // E.g., if the charTable is 28 characters in length, then the binary\n        // digit representing 27 (the last item in the array) is:\n        //\n        //   1 1011\n        //\n        // So the width is determined to be 5. If the pointer range has a\n        // maximum of 250, represented in binary as:\n        //\n        //   1111 1010\n        //\n        // Giving a width of 8. With these specifications, a node such as:\n        //\n        //   charIndex: 8, pointer: 100, last: false\n        //\n        // Would be encoded as:\n        //\n        //   --A---|----B-----|C|XXXXX\n        //   0100 0|011 0010 0|1|00 00\n        //\n        // Which can be represented in Base64 as:\n        //\n        //   QyQ==\n        //\n        // TODO could be more clever and combine the first two fields.\n\n        const encodedTrie = new BinaryString();\n\n        chunks.forEach(chunk => {\n            let { char, offset, last } = chunk;\n            encodedTrie.write(charMap[char], charEncodingWidth);\n            encodedTrie.write(offset - offsetMin, pointerEncodingWidth);\n            encodedTrie.write(+last, 1);\n        });\n\n        encodedTrie.flush();\n\n        // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        // Encode header\n        // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n        const headerString = new BinaryString();\n        // TODO encode unicode\n        const outputCharTable = charTableAsArray.join('');\n\n        // Header width designates the ASCII-character count at the beginning\n        // of the file that encodes the header.\n        const headerWidth = Math.ceil((\n            HEADER_WIDTH_FIELD +\n            VERSION_FIELD +\n            OFFSET_SIGN_FIELD +\n            OFFSET_VAL_FIELD +\n            CHAR_WIDTH_FIELD +\n            POINTER_WIDTH_FIELD\n        ) / 6) + outputCharTable.length;\n        // Mark the offset as positive or negative\n        const offsetSign = +(offsetMin < 0);\n\n        headerString.write(headerWidth, HEADER_WIDTH_FIELD);\n        headerString.write(VERSION, VERSION_FIELD);\n        headerString.write(offsetSign, OFFSET_SIGN_FIELD);\n        headerString.write(offsetSign ? -offsetMin : offsetMin, OFFSET_VAL_FIELD);\n        headerString.write(charEncodingWidth, CHAR_WIDTH_FIELD);\n        headerString.write(pointerEncodingWidth, POINTER_WIDTH_FIELD);\n        headerString.flush();\n\n        // Concat the header, charTable, and trie\n        return `${headerString.getData()}${outputCharTable}${encodedTrie.getData()}`;\n    }\n\n    /**\n     * Implement JSON API for serialization. Tries can be serialized and\n     * restored using JSON and the constructor. Note that tries (even frozen\n     * ones) *do not serialize efficiently in JSON*. For memory-efficient\n     * tries, @see Trie#encode.\n     *\n     * @example\n     *   > trie = new Trie();\n     *   > ['foo', 'fudge', 'nudge'].forEach(s => trie.insert(s));\n     *   > let jsonStr = JSON.stringify(trie);\n     *   > let restored = new Trie(JSON.parse(jsonStr));\n     *   > ['foo', 'fudge', 'nudge'].every(s => restored.test(s));\n     *   // -> true\n     *\n     * @return {Object} Vanilla JS object\n     */\n    toJSON() {\n        // Remove any private fields on serialization, e.g. __visited__\n        let str = JSON.stringify(this.root, (k, v) => {\n             if (k[1] === '_') {\n                return undefined;\n             }\n             return v;\n        });\n        return JSON.parse(str);\n    }\n\n}\n","/**\n * @file Lookup tables for Base64 conversions\n */\n\n/**\n * Lookup table for transforming a 6-bit binary integer into a Base-64 ASCII\n * character.\n * @constant {String[]}\n */\nexport const BASE64_INT_TO_CHAR = `\\\nABCDEFGHIJKLMNOPQRSTUVWXYZ\\\nabcdefghijklmnopqrstuvwxyz\\\n0123456789\\\n+/\\\n`.split('');\n\n/**\n * Inverse lookup table for transformating a Base-64 ASCII character into the\n * corresponding integer value.\n * @constant {Object}\n */\nexport const BASE64_CHAR_TO_INT = BASE64_INT_TO_CHAR.reduce((agg, char, i) => {\n    agg[char] = i;\n    return agg;\n}, {} as {[key: string]: number});\n","/**\n * @file Parameters used for encoding\n */\n\n/**\n * String terminal character\n * @constant {String}\n */\nexport const TERMINAL = '\\0';\n\n/**\n * Terminal edge\n * @constant {Object}\n */\nexport const TERMINUS = Object.create(null);\n\n/**\n * Encoding version. Bump when breaking encoding changes are introduced.\n * @constant {Number}\n */\nexport const VERSION = 0;\n\n/**\n * Width of header field storing entire header width (including char table).\n * Value is given in Base64 characters (i.e., every six bits)\n * @constant {Number}\n */\nexport const HEADER_WIDTH_FIELD = 10;\n\n/**\n * Width of version field\n * @type {Number}\n */\nexport const VERSION_FIELD = 10;\n\n/**\n * Width of header field representing sign of offset\n * @constant {Number}\n */\nexport const OFFSET_SIGN_FIELD = 1;\n\n/**\n * Width of header field representing unsigned value of offset\n * @constant {Number}\n */\nexport const OFFSET_VAL_FIELD = 21;\n\n/**\n * Width of header field representing the width of the char index in a word\n * @constant {Number}\n */\nexport const CHAR_WIDTH_FIELD = 8;\n\n/**\n * Width of header field representing the width of the offset pointer in a word\n * @constant {Number}\n */\nexport const POINTER_WIDTH_FIELD = 8;\n","/**\n * @file Provides a fast floor_log2 function\n */\n\n/**\n * Fast floor(log2(x)) operation\n * @param  {Number} x\n * @return {Number}\n */\nexport function floor_log2(x: number) {\n    let n = 0;\n    while (x >>= 1) {\n        n++;\n    }\n    return n;\n}\n","/**\n * @file Convenient functional tools for creating Tries from arrays\n */\n\nimport {Trie} from './Trie';\nexport {Trie} from './Trie';\n\n/**\n * Synchronously construct a new Trie out of the given strings.\n * @param  {String[]} words\n * @return {Trie}\n */\nexport function createSync(strings: string[]) {\n    const trie = new Trie();\n\n    strings.forEach(s => trie.insert(s));\n\n    return trie;\n}\n\n/**\n * Create a frozen Trie out of given words\n * @param  {String[]} words\n * @return {Trie}\n */\nexport function createFrozenSync(words: string[]) {\n    return createSync(words).freeze();\n}\n"],"sourceRoot":""}